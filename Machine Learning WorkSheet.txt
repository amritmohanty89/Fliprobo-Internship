1) The value of correlation coefficient will always be: between -1 and 1.

Ans::C

2) Which of the following cannot be used for dimensionality reduction?

Ans::C::Recursive feature elimination

3) Which of the following is not a kernel in Support Vector Machines?

Ans::B::Radial Basis Function

4) Amongst the following, which one is least suitable for a dataset having non-linear decision boundaries?

Ans::A::Logistic Regession

5) In a Linear Regression problem, ‘X’ is independent variable and ‘Y’ is dependent variable, where ‘X’ represents weight in pounds. If you convert the unit of ‘X’ to kilograms, then new coefficient of ‘X’ will be?

Ans::C:: Old coefficient of ‘X’ ÷ 2.205

6) As we increase the number of estimators in ADABOOST Classifier, what happens to the accuracy of the model?

Ans::B::increases

7) Which of the following is not an advantage of using random forest instead of decision trees?

Ans::B::Random Forests explains more variance in data then decision trees

8) Which of the following are correct about Principal Components?

Ans::D::All of the above

9) Which of the following are applications of clustering?

Ans::C::Identifying Identifying spam or ham emails

10) Which of the following is(are) hyper parameters of a decision tree?

Ans::A:max_depth

11) Outlier is an obervation that lies an abnormal distance from other values in a random sample from a population.

The interquartaile range (IQR) is a mesure of variability, based on dividing a set into quartiles.

Quartile divide a rank ordered data set into four equal parts. The values that divide each part are called as first, second and third quartile respectively.

12) Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi-sets of the original data. Boosting is an iterative technique which adjusts the weight of an observation based on the last classification.

13) R-squared is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression. r2 100% indicates that the model explains all the variability of the response data around its mean.
Adjusted R-squared value can be calculated based on value of r-squared, number of independent variables (predictors), total sample size. Every time you add a independent variable to a model, the R-squared increases, even if the independent variable is insignificant. It never declines.
R^{2}_{\text{McFadden}} = 1- \frac{log(L_c)}{log(L_{\text{null}})}

14) Normalization typically means rescales the values into a range of [0,1]. Standardization typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance).

15) Cross-validation is a statistical method used to estimate the skill of machine learning models. Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.
The advantage of this method is that the proportion of the validation or training split is not dependent on the number of folds (K-fold test). However, there is a disadvantage as well. There are chances that you might miss out some observations whereas you might select some observations more than once.


